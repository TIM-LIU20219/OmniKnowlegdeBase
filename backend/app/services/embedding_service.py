"""Embedding service for generating document embeddings."""

import logging
import os
from typing import List, Optional

from sentence_transformers import SentenceTransformer

logger = logging.getLogger(__name__)

# Default embedding model
DEFAULT_MODEL = "all-MiniLM-L6-v2"


class EmbeddingService:
    """Service for generating text embeddings."""

    def __init__(self, model_name: Optional[str] = None):
        """
        Initialize embedding service.

        Args:
            model_name: Name of the sentence transformer model to use.
                       If None, uses DEFAULT_MODEL or EMBEDDING_MODEL env var.
        """
        if model_name is None:
            model_name = os.getenv("EMBEDDING_MODEL", DEFAULT_MODEL)

        self.model_name = model_name
        self._model: Optional[SentenceTransformer] = None

        logger.info(f"Initialized embedding service with model: {model_name}")

    @property
    def model(self) -> SentenceTransformer:
        """
        Get or load the embedding model.

        Returns:
            SentenceTransformer model instance
        """
        if self._model is None:
            try:
                logger.info(f"Loading embedding model: {self.model_name}")
                self._model = SentenceTransformer(self.model_name)
                logger.info("Embedding model loaded successfully")
            except Exception as e:
                logger.error(f"Error loading embedding model: {e}")
                raise

        return self._model

    def embed_text(self, text: str) -> List[float]:
        """
        Generate embedding for a single text.

        Args:
            text: Text to embed

        Returns:
            List of embedding values
        """
        try:
            embedding = self.model.encode(text, convert_to_numpy=True)
            return embedding.tolist()
        except Exception as e:
            logger.error(f"Error generating embedding: {e}")
            raise

    def embed_texts(self, texts: List[str], batch_size: int = 32) -> List[List[float]]:
        """
        Generate embeddings for multiple texts.

        Args:
            texts: List of texts to embed
            batch_size: Batch size for processing

        Returns:
            List of embeddings (each is a list of floats)
        """
        if not texts:
            return []

        try:
            embeddings = self.model.encode(
                texts, batch_size=batch_size, convert_to_numpy=True
            )
            return embeddings.tolist()
        except Exception as e:
            logger.error(f"Error generating embeddings: {e}")
            raise

    def get_embedding_dimension(self) -> int:
        """
        Get the dimension of embeddings generated by this model.

        Returns:
            Embedding dimension
        """
        # Test with a dummy text to get dimension
        test_embedding = self.embed_text("test")
        return len(test_embedding)

