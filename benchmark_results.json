{
  "dataset_name": "foundation_llms_benchmark",
  "total_questions": 6,
  "summary": {
    "total_questions": 6,
    "retrieval_metrics": {
      "mean_precision": 0.8333333333333334,
      "mean_recall": 0.8333333333333334,
      "mean_f1": 0.8333333333333334,
      "mean_reciprocal_rank": 0.8333333333333334,
      "mean_similarity_score": 0.4118608981370926,
      "top_k_accuracy": {
        "top_1_accuracy": 0.8333333333333334,
        "top_3_accuracy": 0.8333333333333334
      }
    },
    "context_metrics": {
      "mean_context_length": 3660.3333333333335,
      "mean_retrieval_count": 4.0
    }
  },
  "detailed_results": [
    {
      "question_id": "foundation_llm_001",
      "question": "什么是语言模型？语言模型的基本原理是什么？",
      "ground_truth_answer": "语言模型是一种概率模型，用于预测给定上下文的下一个词或字符的概率分布。语言模型的基本原理是通过学习大量文本数据，建立词汇序列的概率分布，从而能够预测和生成文本。",
      "retrieved_doc_ids": [
        "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f",
        "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f",
        "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f",
        "6f45e736-c458-4444-a4e1-dee2a825bc03"
      ],
      "expected_doc_ids": [
        "37096bfa-1bb2-4571-8dd7-9d1fbd6d91b6"
      ],
      "sources": [
        {
          "chunk_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f_chunk_2",
          "title": "第2章 大语言模型架构",
          "doc_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f",
          "distance": 0.6558382511138916,
          "chunk_content": "李佳晖毛玉仁宓禹\n和研究机构也纷纷推出了自己的模型，例如百川智能的百川大模型[44]，百度的文\n心一言等，推动了大语言模型的快速发展。 本节将深入剖析大型语言模型的发展历程，特别是在能力增强和新能力涌现\n方面的进展。我们将从模型规模和数据规模的增长出发，探讨这些因素如何共同\n作用，促进了模型性能的飞跃和新功能的出现。 2.1.1 大数据+ 大模型→能力增强\n在数字化浪潮的推动下，数据如同汇聚的洪流，而模型则如同乘风破浪的巨\n舰。数据规模的增长为模型提供了更丰富的信息源，意味着模型可以学习到更多样\n化的语言模式和深层次的语义关系。而模型规模的不断扩大，极大地增加了模型\n的表达能力，使其能够捕捉到更加细微的语言特征和复杂的语言结构。在如此庞\n大的模型参数规模以及多样化的训练数据共同作用下，模型内在对数据分布的拟\n合能力不断提升，从而在复杂多变的数据环境中表现出更高的适应性和有效性[7]。 然而模型规模和数据规模的增长并非没有代价，它们带来了更高的计算成本\n和存储需求，这要求我们在模型设计时必须在资源消耗和性能提升之间找到一个\n恰当的平衡点。为了应对这一挑战，大语言模型的扩展法则（Scaling Laws）应运\n而生。这些法则揭示了模型的能力随模型和数据规模的变化关系，为大语言模型的\n设计和优化提供了宝贵的指导和参考。本章节将深入介绍两种扩展法则：OpenAI\n提出的Kaplan-McCandlish 扩展法则以及DeepMind 提出的Chinchilla 扩展法则。 1. Kaplan-McCandlish 扩展法则\n2020 年，OpenAI 团队的Jared Kaplan 和Sam McCandlish 等人[16] 首次探究\n了神经网络的性能与数据规模D 以及模型规模N 之间的函数关系。他们在不同规\n模的数据集（从2200 万到230 亿个Token）和不同规模的模型下（从768 到15 亿\n个参数）进行实验，并根据实验结果拟合出了两个基本公式： 35"
        },
        {
          "chunk_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f_chunk_5",
          "title": "第2章 大语言模型架构",
          "doc_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f",
          "distance": 0.6739352941513062,
          "chunk_content": "第2 章大语言模型架构\n2.1.2 大数据+ 大模型→能力扩展\n如图2.2所示，模型训练数据规模以及参数数量的不断提升，不仅带来了上述\n学习能力的稳步增强，还为大模型“解锁”了一系列新的能力4，例如上下文学习\n能力、常识推理能力、数学运算能力、代码生成能力等。值得注意的是，这些新能\n力并非通过在特定下游任务上通过训练获得，而是随着模型复杂度的提升凭空自\n然涌现5。这些能力因此被称为大语言模型的涌现能力（Emergent Abilities）。 1750亿参数\n复杂逻辑推理\n多模态理解\n多轮对话\n垂域问答\n130亿参数\n上下文学习\n代码生成\n情感分析\n语言理解\n问答任务\n常识推理\n常识推理\n上下文学习\n代码生成\n情感分析\n语言理解\n问答任务\n...\n问答任务\n20亿参数\n语言理解\n情感分析\n系统在某个阈值点发生显著变化，这些能力也并没有一个平滑的、逐渐积累的过\n程，而是在模型达到一定规模和复杂度后，很突然地显现[32]。例如，在GPT 系\n列的演变中，可以观察到一些较为典型的涌现能力。 上下文学习：上下文学习（In-Context Learning）是指大语言模型在推理过程\n中，能够利用输入文本的上下文信息来执行特定任务的能力。具备了上下文\n学习能力的模型，在很多任务中无需额外的训练，仅通过示例或提示即可理\n解任务要求并生成恰当的输出。在GPT 系列中，不同版本的模型在上下文学\n习能力上有显著差异。早期的GPT-1 和GPT-2 在上下文学习方面的能力非常\n4https://research.google/blog/pathways-language-model-palm-scaling-to-540-billion-parameters-forbreakthrough-performance\n5https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models"
        },
        {
          "chunk_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f_chunk_0",
          "title": "第2章 大语言模型架构",
          "doc_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f",
          "distance": 0.677617073059082,
          "chunk_content": "大语言模型架构\n随着数据资源和计算能力的爆发式增长，语言模型的参数规模和性能表现实\n现了质的飞跃，迈入了大语言模型（Large Language Model, LLM）的新时代。 凭借着\n庞大的参数量和丰富的训练数据，大语言模型不仅展现出了强大的泛化能力，还催\n生了新智能的涌现，勇立生成式人工智能（Artificial Intelligence Generated Content,\nAIGC）的浪潮之巅。 当前，大语言模型技术蓬勃发展，各类模型层出不穷。 这些\n模型在广泛的应用场景中已经展现出与人类比肩甚至超过人类的能力，引领着由\nAIGC 驱动的新一轮产业革命。 本章将深入探讨大语言模型的相关背景知识，并分\n别介绍Encoder-only、Encoder-Decoder 以及Decoder-only 三种主流模型架构。 通过\n列举每种架构的代表性模型，深入分析它们在网络结构、训练方法等方面的主要\n创新之处。 最后，本章还将简单介绍一些非Transformer 架构的模型，以展现当前\n大语言模型研究百花齐放的发展现状。 * 本书持续更新，GIT Hub 链接为：https://github. com/ZJU-LLMs/Foundations-of-LLMs。 第2 章大语言模型架构\n2. 1 大数据+ 大模型→新智能\n在自然语言处理的前沿领域，大语言模型正以其庞大的模型规模、海量数据\n的吞吐能力和卓越的模型性能，推动着一场技术革新的浪潮。 当我们谈论“大语言\n模型”之大时，所指的不仅仅是模型规模的庞大，也涵盖了训练数据规模的庞大， 以及由此衍生出的模型能力的强大。 这些模型如同探索未知领域的巨轮，不仅在\n已有的技术上不断突破性能的极限，更在新能力的探索中展现出惊人的潜力。 截止2024 年6 月，国内外已经见证了超过百种大语言模型的诞生，这些大语\n言模型在学术界和工业界均产生了深远的影响。 图2. 1展示了其中一些具有重要影\n响力的模型。"
        },
        {
          "chunk_id": "6f45e736-c458-4444-a4e1-dee2a825bc03_chunk_0",
          "title": "第5章 模型编辑",
          "doc_id": "6f45e736-c458-4444-a4e1-dee2a825bc03",
          "distance": 0.6953108906745911,
          "chunk_content": "模型编辑\n预训练大语言模型中，可能存在偏见、毒性、知识错误等问题。为了纠正这些\n问题，可以将大语言模型“回炉重造”——用清洗过的数据重新进行预训练，但成\n本过高，舍本逐末。此外，也可对大语言模型“继续教育”——利用高效微调技术\n向大语言模型注入新知识，但因为新知识相关样本有限，容易诱发过拟合和灾难\n性遗忘，得不偿失。为此，仅对模型中的特定知识点进行修正的模型编辑技术应运\n而生。本章将介绍模型编辑这一新兴技术，首先介绍模型编辑思想、定义、性质， 其次从内外两个角度分别介绍模型编辑经典方法，然后举例介绍模型编辑的具体\n方法T-Patcher 和ROME，最后介绍模型编辑的实际应用。 * 本书持续更新，GIT Hub 链接为：https://github.com/ZJU-LLMs/Foundations-of-LLMs。 第5 章模型编辑\n5.1 模型编辑简介\n大语言模型有时会产生一些不符合人们期望的结果，如偏见、毒性和知识错\n误等。偏见是指模型生成的内容中包含刻板印象和社会偏见等不公正的观点，毒\n性是指模型生成的内容中包含有害成分，而知识错误则是指模型提供的信息与事\n实不符。例如，当被问到“斑马的皮肤是什么颜色的？”时，ChatGPT 错误地回答\n“肉色”，而实际上斑马的皮肤是黑色的，这就是一个知识错误，如图5.1。如果不\n及时修正这些问题，可能会对人们造成严重误导。 斑马的皮肤是什么颜色的？ 斑马的皮肤颜色是接近肉色的，黑白条纹主要出现在它们的毛发上。 (a) 编辑前模型。 斑马的皮肤是什么颜色的？ 斑马的皮肤本身是黑色的，斑马的黑白条纹是由其毛发的颜色形成的。 (b) 编辑后模型。 图5.1: 大语言模型知识错误示例。 为了纠正这些问题，可以考虑重新预训练和微调两种方法。重新预训练是指\n使用矫正了偏见、祛除了毒性、纠正了知识错误的清洗后的数据对模型进行重新\n预训练。这种方法能够从根本上修复模型的错误输出。然而，清洗数据成本高昂， 并且由于知识可能频繁更新，无法保证清洗过的数据永远是是完美的；而且，重新\n进行预训练需要消耗巨大的计算资源，如果每次发现模型错误时都对其重新预训\n练，未免舍本逐末。微调则是在预训练模型的基础上，针对其错误进一步调整模型"
        }
      ],
      "metadata": {
        "retrieved_count": 4,
        "context_length": 3751
      }
    },
    {
      "question_id": "foundation_llm_002",
      "question": "大语言模型的架构有哪些主要类型？",
      "ground_truth_answer": "大语言模型的主要架构类型包括Transformer架构、GPT系列（生成式预训练模型）、BERT系列（双向编码器表示）、T5（文本到文本转换模型）等。",
      "retrieved_doc_ids": [
        "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f",
        "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f",
        "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f",
        "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f"
      ],
      "expected_doc_ids": [
        "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f"
      ],
      "sources": [
        {
          "chunk_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f_chunk_0",
          "title": "第2章 大语言模型架构",
          "doc_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f",
          "distance": 0.3988844156265259,
          "chunk_content": "大语言模型架构\n随着数据资源和计算能力的爆发式增长，语言模型的参数规模和性能表现实\n现了质的飞跃，迈入了大语言模型（Large Language Model, LLM）的新时代。 凭借着\n庞大的参数量和丰富的训练数据，大语言模型不仅展现出了强大的泛化能力，还催\n生了新智能的涌现，勇立生成式人工智能（Artificial Intelligence Generated Content,\nAIGC）的浪潮之巅。 当前，大语言模型技术蓬勃发展，各类模型层出不穷。 这些\n模型在广泛的应用场景中已经展现出与人类比肩甚至超过人类的能力，引领着由\nAIGC 驱动的新一轮产业革命。 本章将深入探讨大语言模型的相关背景知识，并分\n别介绍Encoder-only、Encoder-Decoder 以及Decoder-only 三种主流模型架构。 通过\n列举每种架构的代表性模型，深入分析它们在网络结构、训练方法等方面的主要\n创新之处。 最后，本章还将简单介绍一些非Transformer 架构的模型，以展现当前\n大语言模型研究百花齐放的发展现状。 * 本书持续更新，GIT Hub 链接为：https://github. com/ZJU-LLMs/Foundations-of-LLMs。 第2 章大语言模型架构\n2. 1 大数据+ 大模型→新智能\n在自然语言处理的前沿领域，大语言模型正以其庞大的模型规模、海量数据\n的吞吐能力和卓越的模型性能，推动着一场技术革新的浪潮。 当我们谈论“大语言\n模型”之大时，所指的不仅仅是模型规模的庞大，也涵盖了训练数据规模的庞大， 以及由此衍生出的模型能力的强大。 这些模型如同探索未知领域的巨轮，不仅在\n已有的技术上不断突破性能的极限，更在新能力的探索中展现出惊人的潜力。 截止2024 年6 月，国内外已经见证了超过百种大语言模型的诞生，这些大语\n言模型在学术界和工业界均产生了深远的影响。 图2. 1展示了其中一些具有重要影\n响力的模型。"
        },
        {
          "chunk_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f_chunk_7",
          "title": "第2章 大语言模型架构",
          "doc_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f",
          "distance": 0.505081057548523,
          "chunk_content": "第2 章大语言模型架构\n预训练模型，在逻辑推理方面的能力非常有限，甚至对于130 亿参数版本的\nGPT-3 模型而言，虽然能处理一部分逻辑推理任务，但在复杂度和精确性上\n仍存在一定局限性。直到1750 亿参数版本，GPT-3 才能够处理复杂的逻辑推\n理任务，生成详细和连贯的推理过程。 ...\n这些涌现能力使得大语言模型可以在不进行专项训练的前提下完成各类任务， 但同时也带来了诸多挑战，包括模型的可解释性、信息安全与隐私、伦理和公平性\n问题，以及对计算资源的巨大需求等。解决这些挑战需要在技术、法律和社会层面\n进行综合考量，以确保大语言模型的健康发展和可持续进步。 2.2 大语言模型架构概览\n在语言模型的发展历程中，Transformer[42] 框架的问世代表着一个划时代的\n转折点。其独特的自注意力（Self-Attention）机制极大地提升了模型对序列数据的\n处理能力，在捕捉长距离依赖关系方面表现尤为出色。此外，Transformer 框架对\n并行计算的支持极大地加速了模型的训练过程。当前，绝大多数大语言模型均以\nTransformer 框架为核心，并进一步演化出了三种经典架构，分别是Encoder-only 架\n构，Decoder-only 架构以及Encoder-Decoder 架构。这三种架构在设计和功能上各\n有不同。本节将简要介绍这三种架构的设计理念与预训练方式，并分析它们之间\n的区别以及各自的演变趋势。 2.2.1 主流模型架构的类别\n本小节将从设计理念、训练方式等角度对Encoder-only 架构，Decoder-only 架\n构以及Encoder-Decoder 架构分别进行简要介绍。 40"
        },
        {
          "chunk_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f_chunk_66",
          "title": "第2章 大语言模型架构",
          "doc_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f",
          "distance": 0.5621550679206848,
          "chunk_content": "第2 章大语言模型架构\n[29]\nColin Raffel et al. “Exploring the limits of transfer learning with a unified text-totext transformer”. In: Journal of machine learning research 21. 140 (2020), pp. 1–\n67. [30]\nBaptiste Roziere et al. “Code llama: Open foundation models for code”. In: arXiv\npreprint arXiv:2308. 12950 (2023). [31]\nVictor Sanh et al. “Multitask prompted training enables zero-shot task generalization”. In: arXiv preprint arXiv:2110. 08207 (2021). [32]\nRylan Schaeffer, Brando Miranda, and Sanmi Koyejo. “Are emergent abilities of\nlarge language models a mirage? ” In: NeurIPS. 2024. [33]\nJohn Schulman et al. “Proximal policy optimization algorithms”. In: arXiv preprint\n[34]\nNoam\nShazeer. “Glu\nvariants\nimprove\ntransformer”. In:\narXiv\npreprint\n[35]\nShaden Smith et al. “Using deepspeed and megatron to train megatronturing nlg 530b, a large-scale generative language model”. In: arXiv preprint\n[36]\nJianlin Su et al. “Roformer: Enhanced transformer with rotary position embedding”."
        },
        {
          "chunk_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f_chunk_5",
          "title": "第2章 大语言模型架构",
          "doc_id": "a2c90612-5afc-4b3a-b1a1-bcfbd097e03f",
          "distance": 0.5660839080810547,
          "chunk_content": "第2 章大语言模型架构\n2.1.2 大数据+ 大模型→能力扩展\n如图2.2所示，模型训练数据规模以及参数数量的不断提升，不仅带来了上述\n学习能力的稳步增强，还为大模型“解锁”了一系列新的能力4，例如上下文学习\n能力、常识推理能力、数学运算能力、代码生成能力等。值得注意的是，这些新能\n力并非通过在特定下游任务上通过训练获得，而是随着模型复杂度的提升凭空自\n然涌现5。这些能力因此被称为大语言模型的涌现能力（Emergent Abilities）。 1750亿参数\n复杂逻辑推理\n多模态理解\n多轮对话\n垂域问答\n130亿参数\n上下文学习\n代码生成\n情感分析\n语言理解\n问答任务\n常识推理\n常识推理\n上下文学习\n代码生成\n情感分析\n语言理解\n问答任务\n...\n问答任务\n20亿参数\n语言理解\n情感分析\n系统在某个阈值点发生显著变化，这些能力也并没有一个平滑的、逐渐积累的过\n程，而是在模型达到一定规模和复杂度后，很突然地显现[32]。例如，在GPT 系\n列的演变中，可以观察到一些较为典型的涌现能力。 上下文学习：上下文学习（In-Context Learning）是指大语言模型在推理过程\n中，能够利用输入文本的上下文信息来执行特定任务的能力。具备了上下文\n学习能力的模型，在很多任务中无需额外的训练，仅通过示例或提示即可理\n解任务要求并生成恰当的输出。在GPT 系列中，不同版本的模型在上下文学\n习能力上有显著差异。早期的GPT-1 和GPT-2 在上下文学习方面的能力非常\n4https://research.google/blog/pathways-language-model-palm-scaling-to-540-billion-parameters-forbreakthrough-performance\n5https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models"
        }
      ],
      "metadata": {
        "retrieved_count": 4,
        "context_length": 3673
      }
    },
    {
      "question_id": "foundation_llm_003",
      "question": "什么是Prompt工程？Prompt工程的主要技术有哪些？",
      "ground_truth_answer": "Prompt工程是指设计和优化输入提示词（prompt）以引导大语言模型生成期望输出的技术。主要技术包括few-shot learning、chain-of-thought prompting、role prompting等。",
      "retrieved_doc_ids": [
        "a0a5b7b8-4e12-4f8c-aaea-87af2ced3794",
        "a0a5b7b8-4e12-4f8c-aaea-87af2ced3794",
        "a0a5b7b8-4e12-4f8c-aaea-87af2ced3794",
        "a0a5b7b8-4e12-4f8c-aaea-87af2ced3794"
      ],
      "expected_doc_ids": [
        "a0a5b7b8-4e12-4f8c-aaea-87af2ced3794"
      ],
      "sources": [
        {
          "chunk_id": "a0a5b7b8-4e12-4f8c-aaea-87af2ced3794_chunk_9",
          "title": "第3章 Prompt 工程",
          "doc_id": "a0a5b7b8-4e12-4f8c-aaea-87af2ced3794",
          "distance": 0.6108278036117554,
          "chunk_content": "第3 章Prompt 工程\n工程方法在Spider [44] 榜单上取得了突破性成绩，超越了传统的微调方法。此外， 在知识密集型任务问答领域MMLU [9] 等多个领域，基于Prompt 工程的方法也取\n得最佳效果。 2. 数据增强\n应用Prompt 工程通过大语言模型来进行数据增强，不仅能够提升现有数据集\n的质量，还能够生成新的高质量数据。这些数据可以用于训练和优化其它模型，以\n将大语言模型的能力以合成数据的方法“蒸馏”到其他模型上。例如，我们可以引\n导ChatGPT 模型生成包含丰富推理步骤的数据集，用于增强金融领域Text-to-SQL\n模型的推理能力[45]。此外，通过精心设计的提示，还能生成包含复杂指令的数据\n集，如Alpaca [32] 和Evol-Instruct [21]。将这些合成的数据集用于微调参数量较小\n的模型，可以其在保持较小模型尺寸和低计算成本的同时，接近大型模型的性能。 3. 智能代理\n应用Prompt 工程可以将大语言模型构建为智能代理（Intelligent Agent，IA）5。 智能代理，又叫做智能体，能够感知环境、自主采取行动以实现目标，并通过学习\n或获取知识来提高其性能。在智能代理进行感知环境、采取行动、学习知识的过程\n中，都离不开Prompt 工程。例如，斯坦福大学利用GPT-4 模拟了一个虚拟西部小\n镇[25]，多个基于GPT-4 的智能体在其中生活和互动，他们根据自己的角色和目\n标自主行动，进行交流，解决问题，并推动小镇的发展。整个虚拟西部小镇的运转\n都是由Prompt 工程驱动的。 本节探讨了Prompt 的概念，Prompt 工程的概念以及意义，揭示了Prompt 在\n大语言模型应用中的关键作用和广阔潜力。接下来，我们将进一步拓展这一主题： 第3.2节将探索上下文学习的相关内容，揭示其在提升模型理解和响应能力中的作\n用；第3.3节将详细介绍思维链提示方法及其变种，展示如何通过这些方法增强模\n5https://en.wikipedia.org/wiki/Intelligent_agent"
        },
        {
          "chunk_id": "a0a5b7b8-4e12-4f8c-aaea-87af2ced3794_chunk_0",
          "title": "第3章 Prompt 工程",
          "doc_id": "a0a5b7b8-4e12-4f8c-aaea-87af2ced3794",
          "distance": 0.6285296082496643,
          "chunk_content": "Prompt 工程\n随着模型训练数据规模和参数数量的持续增长，大语言模型突破了泛化瓶颈， 并涌现出了强大的指令跟随能力。泛化能力的增强使得模型能够处理和理解多种\n未知任务，而指令跟随能力的提升则确保了模型能够准确响应人类的指令。两种\n能力的结合，使得我们能够通过精心编写的指令输入，即Prompt，来引导模型适\n应各种下游任务，从而避免了传统微调方法所带来的高昂计算成本。Prompt 工程， 作为一门专注于如何编写这些有效指令的技术，成为了连接模型与任务需求之间\n的桥梁。它不仅要求对模型有深入的理解，还需要对任务目标有精准的把握。通过\nPrompt 工程，我们能够最大化地发挥大语言模型的潜力，使其在多样化的应用场\n景中发挥出卓越的性能。本章将深入探讨Prompt 工程的概念、方法及作用，并介\n绍上下文学习、思维链等技术，以及Prompt 工程的相关应用。 * 本书持续更新，GIT Hub 链接为：https://github.com/ZJU-LLMs/Foundations-of-LLMs。 第3 章Prompt 工程\n3.1 Prompt 工程简介\n传统的自然语言处理研究遵循“预训练-微调-预测”范式，即先在大规模语料\n库上作预训练，然后在下游任务上微调，最后在微调后的模型上进行预测。然而， 随着语言模型在规模和能力上的显著提升，一种新的范式——“预训练-提示预测”\n应运而生，即在预训练模型的基础上，通过精心设计Prompt 引导大模型直接适应\n下游任务，而无需进行繁琐微调，如图3.1所示。在这一过程中，Prompt 的设计将\n对模型性能产生深远影响。这种专注于如何编写Prompt 的技术，被称为Prompt\n工程。在本节中，我们将深入介绍Prompt 工程的定义及其相关概念，探讨其在自\n然语言处理领域中的重要性和应用。 图3.1: “预训练-微调-预测”范式与“预训练-提示预测”范式对比。 3.1.1 Prompt 的定义\nPrompt 是指用于指导生成式人工智能模型执行特定任务的输入指令1，这些指\n令通常以自然语言文本的形式出现。Prompt 的核心目的是清晰地描述模型应该执\n行的任务，以引导模型生成特定的文本、图像、音频等内容。如图3.2所示，通过\n1https://en.wikipedia.org/wiki/Prompt_engineering"
        },
        {
          "chunk_id": "a0a5b7b8-4e12-4f8c-aaea-87af2ced3794_chunk_46",
          "title": "第3章 Prompt 工程",
          "doc_id": "a0a5b7b8-4e12-4f8c-aaea-87af2ced3794",
          "distance": 0.7137033939361572,
          "chunk_content": "第3 章Prompt 工程\n通过情景代入，模型能够深入理解并反映特定情境下的文化社会背景与现实\n环境，从而生成更加丰富和有深度的回答。在图3.29例子中，当模型被置于90 年\n代的街头情景中，它不仅能够描述小浣熊干脆面的口味，还能够捕捉到那个时代\n特有的文化现象——通过收集卡片来交换乐趣。这种回答不仅提供了具体的信息， 还唤起了用户的情感共鸣，增强了交互的情感连接。 在本节中，我们深入探讨了提升Prompt 技巧的多种策略，以增强大语言模型\n的交互效率和输出质量。这些技巧主要包括规范Prompt 编写、合理归纳提问、适\n时使用思维链、以及善用心理暗示。这些技巧和策略的应用，不仅可以提升了提示\n的有效性，使得模型能够更准确地理解和回应用户的需求，还显著提高了大语言\n模型在复杂任务中的表现。 3.5 相关应用\nPrompt 工程的应用极为广泛，几乎涵盖了所有需要与大语言模型进行高效交\n互的场景。这项技术不仅能够帮助我们处理一些基础任务，还能显著提升大语言\n模型在应对复杂任务时的表现。Prompt 工程在构建Agent 完成复杂任务、进行数\n据合成、Text-to-SQL 转换，以及设计个性化的GPTs 等方面，发挥着不可或缺的作\n用。下面我们将依次介绍Prompt 工程在这些应用场景中的具体作用。 3.5.1 基于大语言模型的Agent\n智能体（Agent）是一种能够自主感知环境并采取行动以实现特定目标的实\n体[35]。作为实现通用人工智能（AGI）的有力手段，Agent 被期望能够完成各种复\n杂任务，并在多样化环境中表现出类人智能。然而，以往的Agent 通常依赖简单的\n启发式策略函数，在孤立且受限的环境中进行学习和操作，这种方法难以复制人\n类水平的决策过程，限制了Agent 的能力和应用范围。近年来，大语言模型的不断"
        },
        {
          "chunk_id": "a0a5b7b8-4e12-4f8c-aaea-87af2ced3794_chunk_59",
          "title": "第3章 Prompt 工程",
          "doc_id": "a0a5b7b8-4e12-4f8c-aaea-87af2ced3794",
          "distance": 0.7507379055023193,
          "chunk_content": "第3 章Prompt 工程\n[9]\nDan Hendrycks et al. “Measuring Massive Multitask Language Understanding”. In:\nICLR. 2021. [10]\nSepp Hochreiter and Jürgen Schmidhuber. “Long Short-Term Memory”. In: Neural\nComputation 9. 8 (1997), pp. 1735–1780. [11]\nHuiqiang Jiang et al. “LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models”. In: EMNLP. 2023. [12]\nTakeshi Kojima et al. “Large Language Models are Zero-Shot Reasoners”. In:\nNeurIPS. 2022. [13]\nAobo Kong et al. “Better Zero-Shot Reasoning with Role-Play Prompting”. In:\narXiv preprint arXiv:2308. 07702 (2023). [14]\nJannik Kossen, Yarin Gal, and Tom Rainforth. “In-Context Learning Learns\nLabel Relationships but Is Not Conventional Learning”. In: arXiv preprint\n[15]\nJunlong Li et al. “Self-Prompting Large Language Models for Zero-Shot OpenDomain QA”. In: arXiv preprint arXiv:2212. 08635 (2024). [16]\nXiaonan Li et al. “Unified Demonstration Retriever for In-Context Learning”. In:\nACL. 2023. [17]\nJiachang Liu et al."
        }
      ],
      "metadata": {
        "retrieved_count": 4,
        "context_length": 3946
      }
    },
    {
      "question_id": "foundation_llm_004",
      "question": "参数高效微调（PEFT）有哪些方法？",
      "ground_truth_answer": "参数高效微调的主要方法包括LoRA（Low-Rank Adaptation）、Adapter、Prefix Tuning、P-Tuning等，这些方法只训练模型的一小部分参数，从而降低计算成本和存储需求。",
      "retrieved_doc_ids": [
        "14e2c926-0415-4065-b47f-55907fd17ae5",
        "14e2c926-0415-4065-b47f-55907fd17ae5",
        "14e2c926-0415-4065-b47f-55907fd17ae5",
        "14e2c926-0415-4065-b47f-55907fd17ae5"
      ],
      "expected_doc_ids": [
        "14e2c926-0415-4065-b47f-55907fd17ae5"
      ],
      "sources": [
        {
          "chunk_id": "14e2c926-0415-4065-b47f-55907fd17ae5_chunk_3",
          "title": "第4章 参数高效微调",
          "doc_id": "14e2c926-0415-4065-b47f-55907fd17ae5",
          "distance": 0.42905813455581665,
          "chunk_content": "第4 章参数高效微调\n可调参数\n冻结参数\n低秩适配方法\n参数选择方法\n选择参数\n低秩参数\n参数附加方法\n附加参数\n外部参数\n内部参数\n练模型进行微调，在给定指令和输入的情况下，通过顺序预测输出中的每个\ntoken 来训练模型。经过微调的大语言模型能够显著提升指令遵循（Instructionfollowing）能力，这有助于增强其推理水平，泛化到新任务和新领域。 尽管指令微调能有效帮助大语言模型理解新领域的数据知识，提高大语言模\n型在下游任务上的性能。然而，监督微调需要较大的计算资源，以LLaMA2-7B [40]\n模型为例，直接进行全量微调需要近60GB 内存，普通的消费级GPU（如RTX4090\n（24GB））无法完成微调。因此，为了在资源受限的环境中有效微调大语言模型，研\n究参数高效的微调技术显得尤为重要。 4.1.2 参数高效微调\n参数高效微调（Parameter-Eﬀicient Fine-Tuning，PEFT）旨在避免微调全部参\n数，减少在微调过程中需要更新的参数数量和计算开销，从而提高微调大语言模\n型的效率。主流的PEFT 方法可以分为三类：参数附加方法（Additional Parameters\nMethods），参数选择方法（Parameter Selection Methods）以及低秩适配方法（LowRank Adaptation Methods），其方法思想如图4.2 所示。 154"
        },
        {
          "chunk_id": "14e2c926-0415-4065-b47f-55907fd17ae5_chunk_35",
          "title": "第4章 参数高效微调",
          "doc_id": "14e2c926-0415-4065-b47f-55907fd17ae5",
          "distance": 0.5113478899002075,
          "chunk_content": "第4 章参数高效微调\n[38]\nYing Sheng et al. “S-LoRA: Serving Thousands of Concurrent LoRA Adapters”. [39]\nYi-Lin Sung, Varun Nair, and Colin Raffel. “Training Neural Networks with Fixed\nSparse Masks”. In: NIPS. 2021. [40]\nHugo Touvron et al. “Llama 2: Open foundation and fine-tuned chat models”. In:\narXiv preprint arXiv:2307. 09288 (2023). [41]\nMojtaba Valipour et al. “Dylora: Parameter eﬀicient tuning of pre-trained\nmodels using dynamic search-free low-rank adaptation”. In: arXiv preprint\n[42]\nMojtaba Valipour et al. “DyLoRA: Parameter-Eﬀicient Tuning of Pre-trained Models using Dynamic Search-Free Low-Rank Adaptation”. In: EACL. 2023. [43]\nZhongwei Wan et al. “Eﬀicient Large Language Models: A Survey”. In: arXiv\npreprint arXiv:2312. 03863 (2023). [44]\nAlex Wang et al. “GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding”. In: ICLR. 2019. [45]\nHanqing Wang et al. “MiLoRA: Harnessing Minor Singular Components for\nParameter-Eﬀicient LLM Finetuning”."
        },
        {
          "chunk_id": "14e2c926-0415-4065-b47f-55907fd17ae5_chunk_4",
          "title": "第4章 参数高效微调",
          "doc_id": "14e2c926-0415-4065-b47f-55907fd17ae5",
          "distance": 0.5166634321212769,
          "chunk_content": "葛宇航毛玉仁\n1. 参数附加方法\n参数附加方法（Additional Parameters Methods）在模型结构中附加新的、较小\n的可训练模块。在进行微调时，将原始模型参数冻结，仅微调这些新加入的模块， 从而来实现高效微调。这些模块通常称为适应层（Adapter Layer）。它们被插入到模\n型的不同层之间，用于捕获特定任务的信息。由于这些新增的适应层参数量很小， 所以参数附加方法能够显著减少需要更新的参数量。典型方法包括：适配器微调\n（Adapter-tuning）[18]、提示微调（Prompt-tuning）[23]、前缀微调（Prefix-tuning）\n参数选择方法（Parameter Selection Methods）仅选择模型的一部分参数进行微\n调，而冻结其余参数。这种方法利用了模型中仅有部分参数对下游任务具有决定\n性作用的特性，“抓住主要矛盾”，仅微调这些关键参数。选择性地微调这些关键\n参数，可以在降低计算负担的同时提升模型的性能。典型的方法包括：BitFit [50]、\nChild-tuning [49] 以及FishMask [39] 等。参数选择方法的将在4.3 节具体介绍。 3. 低秩适配方法\n低秩适配方法（Low-rank Adaptation Methods）通过低秩矩阵来近似原始权重\n更新矩阵，并冻结原始参数矩阵，仅微调低秩更新矩阵。由于低秩更新矩阵的参数\n数量远小于原始的参数更新矩阵，因此大幅节省了微调时的内存开销。LoRA [19]\n是经典的低秩适配方法，后续有AdaLoRA [52]、DyLoRA [42] 以及DoRA [29] 等\n变体被提出，进一步改进了LoRA 性能。低秩适配方法将在4.4 节具体介绍。 4.1.3 参数高效微调的优势\n参数高效微调有以下优势：1) 计算效率高：PEFT 技术减少了需要更新的参数\n数量，从而降低了训练时的计算资源消耗；2）存储效率高：通过减少需要微调的参"
        },
        {
          "chunk_id": "14e2c926-0415-4065-b47f-55907fd17ae5_chunk_5",
          "title": "第4章 参数高效微调",
          "doc_id": "14e2c926-0415-4065-b47f-55907fd17ae5",
          "distance": 0.5350022315979004,
          "chunk_content": "第4 章参数高效微调\n数数量，PEFT 显著降低了微调模型的存储空间，特别适用于内存受限的设备；3）\n适应性强：PEFT 能够快速适应不同任务，而无需重新训练整个模型，使得模型在\n面对变化环境时具有更高的灵活性。 下面我们将通过一个具体案例来深入探讨PEFT 技术如何显著提升参数效率。 具体来说，表4.1 1 详细展示了在配备80GB 显存的A100 GPU 以及64GB 以上CPU\n内存的高性能硬件环境下，对bigscience 模型进行全量微调与采用参数高效微调方\n法LoRA（该方法将在4.4节中详细介绍）时，GPU 内存的消耗情况对比。根据该\n全量参数微调\n参数高效微调(LoRA)\nbigscience/T0_3B\n47.14GB GPU / 2.96GB CPU\n14.4GB GPU / 2.96GB CPU\nbigscience/mt0-xxl (12B params)\nOOM GPU\n56GB GPU / 3GB CPU\nbigscience/bloomz-7b1 (7B params)\nOOM GPU\n32GB GPU / 3.8GB CPU\n表格可以看出，对于80GB 显存大小的GPU，全量参数微调7B/12B 参数的模型， 会导致显存直接溢出。而在使用LoRA 后，显存占用被大幅缩减，使得在单卡上微\n调大语言模型变得可行。 本节首先介绍了对大语言模型进行下游任务适配的两类主流范式：上下文学\n习和指令微调。然而，由于性能和计算成本方面的限制，这两类范式难以适应需\n求。因此，需要研究参数高效微调技术，即PEFT。PEFT 仅对模型的一小部分参数\n进行更新，在保证不牺牲性能的前提下有效减少了模型微调所需的参数量，从而\n节约了计算和存储资源。本节我们对主流PEFT 方法进行了分类，在后续小节中， 我们将根据本节给出的分类学详细介绍主流的三类PEFT 方法：参数附加方法4.2、\n参数选择方法4.3 以及低秩适配方法4.4，并探讨PEFT 的相关应用与实践4.5。 1表格数据来源：https://github.com/huggingface/peft"
        }
      ],
      "metadata": {
        "retrieved_count": 4,
        "context_length": 3626
      }
    },
    {
      "question_id": "foundation_llm_005",
      "question": "什么是模型编辑？模型编辑的主要方法有哪些？",
      "ground_truth_answer": "模型编辑是指在不重新训练整个模型的情况下，修改模型对特定事实或知识的记忆。主要方法包括直接参数修改、知识注入、记忆更新等。",
      "retrieved_doc_ids": [
        "6f45e736-c458-4444-a4e1-dee2a825bc03",
        "6f45e736-c458-4444-a4e1-dee2a825bc03",
        "6f45e736-c458-4444-a4e1-dee2a825bc03",
        "6f45e736-c458-4444-a4e1-dee2a825bc03"
      ],
      "expected_doc_ids": [
        "6f45e736-c458-4444-a4e1-dee2a825bc03"
      ],
      "sources": [
        {
          "chunk_id": "6f45e736-c458-4444-a4e1-dee2a825bc03_chunk_34",
          "title": "第5章 模型编辑",
          "doc_id": "6f45e736-c458-4444-a4e1-dee2a825bc03",
          "distance": 0.5284768342971802,
          "chunk_content": "第5 章模型编辑\n同时保持编辑的特异性和对未见过事实的泛化性。然而，ROME 的编辑目标局限\n于知识元组形式，在处理复杂事实时可能表现不佳，而且不支持批量编辑。其后续\n工作MEMIT [18] 设计了并行的批量编辑技术，能够同时编辑大量事实，提高了编\n辑效率和规模，同时增强了编辑的精度和鲁棒性。 5.5 模型编辑应用\n大语言模型面临着更新成本高、隐私保护难、安全风险大等问题，模型编辑技\n术为解决这些问题提供了新的思路。通过对预训练模型进行细粒度编辑，可以灵\n活地修改和优化模型，而无需从头开始训练，大大降低了模型更新的成本。同时， 模型编辑技术可以针对性地修改特定事实，有效保护隐私信息，降低数据泄露风\n险。此外，通过对模型编辑过程进行精细控制，能够及时识别并消除模型中潜在的\n安全隐患，如有害信息、偏见内容等，从而提升模型的安全性和可靠性。 5.5.1 精准模型更新\n模型编辑技术通过直接修改或增加模型参数，可以巧妙地注入新知识或调整\n模型行为，这为我们提供了一种更精确的模型更新手段。相较于传统的微调方法， 模型编辑减少了对大量数据和计算资源的依赖，也降低了遗忘原有知识的风险。 在实际应用中，Gemini Pro 就有可能使用过模型编辑技术。2023 年12 月，网\n友发现用中文询问“你是谁”这种问题时，Gemini Pro 会回答“我是百度文心大模\n型”。然而，仅仅一天之后，Gemini Pro 便不再回答类似的内容，如图5.21。考虑\n到重新训练模型的成本和时间都是不可接受的，因此有理由猜测Google 使用模型\n编辑技术对Gemini Pro 进行了紧急修复，纠正了模型对类似提问的回答。2\n2https://www.zhihu.com/question/635504283/answer/3330453567\n\n宓禹樊怡江毛玉仁\n模型编辑技术可以快速、精准地修正模型的特定行为。通过识别并修改相关\n的模型参数，可以在短时间内修复模型的回答。这种方法具有外科手术般的精准\n度，能够快速纠正错误或添加新知识，同时最大限度地保留模型原有的能力。它非\n常适用于大语言模型即时更新的场景，使模型能够及时适应新的需求，或纠正现\n有问题，而无需进行昂贵且耗时的全面重新训练。 图5.21: Gemini 回答自己是百度大模型(来自知乎@ 段小草)。 221"
        },
        {
          "chunk_id": "6f45e736-c458-4444-a4e1-dee2a825bc03_chunk_18",
          "title": "第5章 模型编辑",
          "doc_id": "6f45e736-c458-4444-a4e1-dee2a825bc03",
          "distance": 0.5376459360122681,
          "chunk_content": "第5 章模型编辑\n5.2.3 方法比较\n上述各种模型编辑方法各有优劣。本书参考文献[27] 中的实验结果，对主流模\n型编辑方法在各个性质上的表现进行对比，结果如表5.2所示。表中用“高”、\n“中”、\n“低”\n三个级别定性表示方法的准确性、泛化性、可迁移性和局部性，用“\u0013”和“\u0017”来\n表示方法的高效性，即是否支持批量编辑。标注“-”的表明未进行测试。 表5.2: 模型编辑方法比较。 方法\n准确性\n泛化性\n可迁移性\n局部性\n高效性\n外部\n拓展\n法\n知识缓存法\nSERAC\n高\n高\n低\n高\n附加参数法\nCaliNET\n低\n低\n-\n中\nT-Patcher\n高\n高\n高\n中\n内部\n修改\n法\n元学习法\nKE\n低\n低\n-\n高\nMEND\n中\n高\n中\n高\n定位编辑法\nKN\n中\n低\n-\n中\nROME\n高\n高\n高\n高\nMEMIT\n高\n高\n高\n高\n从表5.2中可看出，在外部拓展法中，基于知识缓存的SERAC 在无需额外训\n练的情况下提供了高效的编辑能力，保证了高准确性、泛化性和局部性，适合快速\n响应和批量编辑，但可迁移性较差，编辑缓存和推理模块仍有待优化。基于附加参\n数的CaliNET 和T-Patcher 提供了对模型的直接编辑能力，但CaliNET 对不同模型\n和数据的适应性较差，而T-Patcher 虽然保持了高准确性、泛化性和可迁移性，但\n在批量编辑时，对内存的需求较高。 在内部修改法中，基于元学习法的KE 和MEND 将元知识看作超网络，通过\n使模型“学习如何编辑”，提高了泛化性和训练效率，且支持批量编辑。然而，基\n于元学习的方法训练过程设计较为复杂，在应用于大型模型时可能受限。基于定\n位编辑的KN、ROME 和MEMIT 则专注于精确定位和编辑模型内部的特定知识。 204"
        },
        {
          "chunk_id": "6f45e736-c458-4444-a4e1-dee2a825bc03_chunk_8",
          "title": "第5章 模型编辑",
          "doc_id": "6f45e736-c458-4444-a4e1-dee2a825bc03",
          "distance": 0.5800874829292297,
          "chunk_content": "第5 章模型编辑\n改变，这通常需要更深层次的理解和处理能力。COUNTERFACT 能够评估模型对\n编辑后知识的理解和反应，进而衡量模型的泛化性和局部性。文献[27] 在ZsRE 和\nCOUNTERFACT 数据集的基础上，使用GPT-4 生成相应问题的反向问题、推理问\n题和实体替换问题，构造了可迁移性数据集。 此外，研究者还针对不同领域和任务开发了专门的数据集，如Hallucination[10]\n用于纠正GPT 语言模型中的幻觉，ConvSent[20] 用于评估模型在修改对话代理对\n特定主题的情感时的效果。表5.1从数据类型、样本数量以及输入输出形式方面总\n结了一些模型编辑相关数据集。这些数据集涵盖了从事实检查、知识关联到特定\n领域等多种类型，体现了模型编辑技术在不同场景中的应用潜能。 本节介绍了模型编辑的定义、性质、评估方法以及常用数据集，对模型编辑\n任务做出了详细的解释和说明。接下来，第5.2节将对模型编辑方法进行系统性概\n述，将其分为外部拓展法和内部修改法，并介绍每类方法的代表性工作。第5.3节和\n第5.4节将分别深入探讨外部拓展法中的T-Patcher 方法和内部修改法中的ROME\n方法，通过这两种代表性方法，帮助读者更加细致地理解模型编辑方法的研究过\n程。最后，第5.5节将全面介绍模型编辑的实际应用，并分别举例说明解决思路。 5.2 模型编辑经典方法\n冒险游戏中的勇者需要升级时，可以从内外两个方面进行改造。外部改造主\n要通过置办新的道具和装备，它们能够赋予勇者新的能力，同时保留其原有技能。 内部改造则相当于去锻炼自身，通过增加智力、体力、法力等属性，从自我层面获\n得提升。如果将大语言模型比作冒险游戏中的勇者，那么模型编辑可被看作一种满\n足“升级”需求的方法，可以分别从内外两个角度来考虑。本文参考已有工作[16,\n25, 27, 28]，将现有编辑方法分为外部拓展法和内部修改法。概括来说，外部拓展"
        },
        {
          "chunk_id": "6f45e736-c458-4444-a4e1-dee2a825bc03_chunk_2",
          "title": "第5章 模型编辑",
          "doc_id": "6f45e736-c458-4444-a4e1-dee2a825bc03",
          "distance": 0.5979805588722229,
          "chunk_content": "第5 章模型编辑\n5.1.2 模型编辑定义\n当前，模型编辑领域尚缺乏统一标准，不同研究对相关概念的定义各不相同。 本书将不同工作中提到的基于知识的模型编辑（KME, Knowledge Model Editing）\nEditing）。此外，有些研究用“编辑”（edit）[27] 或“事实”（fact）[17, 18] 来表示\n具体的编辑对象，本书将这些概念统一为“知识点”。 模型编辑的目标可被归纳为：修正大语言模型使其输出期望结果，同时不影\n响其他无关输出。本书将模型编辑定义如下： 定义5.1 (模型编辑)\n将编辑前模型定义为M，编辑后模型定义为M ∗。每一次编辑都修改模型的\n一个知识点k，知识点k 由问题xk 及其对应的答案yk 组成。那么，模型编\n辑的目标可以表示为以下函数： M ∗(x) =\nyk,\n若x = xk 或x与xk相关， M(x),\n若x 与xk无关。 上述定义中有关“相关”和“无关”的判断，涉及到模型编辑的范围问题，本\n书将在第5.1.3小节讨论。 图5.2用“斑马皮肤颜色”这一知识点作为示例，展示了模型编辑的概念。在\n这个示例中，当被询问“斑马的皮肤是什么颜色的？”时，编辑前模型回答了错误\n答案“肉色”，而编辑后的模型可以回答出正确答案“黑色”。 然而，实际的模型编辑过程远比理论定义复杂。这主要源于知识的内在关联\n性：当修改模型对某一特定知识点的认知时，由于该知识点可能与其它知识点相关\n联，所以可能会影响模型对其它相关知识点的理解，从而产生” 牵一发而动全身”\n的效应。因此，如何精确控制模型编辑的范围成为一个关键挑战。精准可控的模型"
        }
      ],
      "metadata": {
        "retrieved_count": 4,
        "context_length": 3524
      }
    },
    {
      "question_id": "foundation_llm_006",
      "question": "什么是检索增强生成（RAG）？RAG的工作原理是什么？",
      "ground_truth_answer": "检索增强生成（RAG）是一种结合信息检索和文本生成的技术。RAG的工作原理是：首先从知识库中检索与查询相关的文档片段，然后将这些片段作为上下文输入到语言模型中，生成基于检索内容的答案。",
      "retrieved_doc_ids": [
        "719f851d-9437-45df-b03d-0e630b2edfed",
        "719f851d-9437-45df-b03d-0e630b2edfed",
        "719f851d-9437-45df-b03d-0e630b2edfed",
        "719f851d-9437-45df-b03d-0e630b2edfed"
      ],
      "expected_doc_ids": [
        "719f851d-9437-45df-b03d-0e630b2edfed"
      ],
      "sources": [
        {
          "chunk_id": "719f851d-9437-45df-b03d-0e630b2edfed_chunk_8",
          "title": "第6章 检索增强生成",
          "doc_id": "719f851d-9437-45df-b03d-0e630b2edfed",
          "distance": 0.47793781757354736,
          "chunk_content": "第6 章检索增强生成\n确定何时需要检索增强，以提升效率并避免干扰信息；（2）何处增强，讨论\n生成过程中插入检索信息的常见位置；（3）多次增强，针对复杂与模糊查询， 讨论常见的多次增强方式；（4）降本增效，介绍现有的知识压缩和缓存加速\n策略。详细内容将在6.4 节介绍。 本节初步介绍了我们为什么需要RAG 和RAG 是什么这两个问题。接下来的\n章节将针对上面提出的三个问题，对具体技术细节详细讨论。 6.2 检索增强生成架构\n检索增强生成（RAG）系统是一个集成了外部知识库、检索器、生成器等多个\n功能模块的软件系统。针对不同的业务场景和需求，可以设计不同的系统架构来\n组合、协调这些模块，以优化RAG 的性能。其中，检索器和生成器的协作方式对\nRAG 性能的影响最为显著。这是因为在不同的协作方式下，检索器检索到的信息\n质量会有所不同，生成器生成的内容质量也会随之变化。此外，检索器和生成器之\n间的协作方式对系统的效率有很大影响。高效的协作能够减少延迟，提高系统的\n响应速度。本节将从如何优化检索器与大语言模型的协作这一角度出发，对经典\nRAG 架构进行梳理和介绍。 6.2.1 RAG 架构分类\n针对不同的业务场景，RAG 中的生成器可以选用不同的大语言模型，如GPT4[1]、LLaMA[49] 等。考虑到大语言模型的开源/闭源、微调成本等问题，RAG 中\n的大语言模型可以是参数不可感知/调节的“黑盒”模型，也可以是参数可感知和\n微调的“白盒”模型。例如，如果选用GPT-4，由于其闭源性，在RAG 过程中只能\n将其视为“黑盒”，只能利用其输出结果，而无法感知/微调其模型参数。如果选择"
        },
        {
          "chunk_id": "719f851d-9437-45df-b03d-0e630b2edfed_chunk_0",
          "title": "第6章 检索增强生成",
          "doc_id": "719f851d-9437-45df-b03d-0e630b2edfed",
          "distance": 0.5084934830665588,
          "chunk_content": "检索增强生成\n在海量训练数据和模型参数的双重作用下，大语言模型展示出了令人惊艳的\n生成能力。 然而，由于训练数据的正确性、时效性和完备性可能存在不足，其难以\n完全覆盖用户的需求；并且，根据“没有免费午餐”[55] 定理，由于参数空间有限， 大语言模型对训练数据的学习也难以达到完美。 上述训练数据和参数学习上的不\n足将导致：大语言模型在面对某些问题时无法给出正确答案，甚至出现“幻觉”， 即生成看似合理实则逻辑混乱或违背事实的回答。 为了解决这些问题并进一步提\n升大语言模型的生成质量，我们可以将相关信息存储在外部数据库中，供大语言模\n型进行检索和调用。 这种从外部数据库中检索出相关信息来辅助改善大语言模型\n生成质量的系统被称之为检索增强生成（Retrieval-Augmented Generation，RAG）。 本章将介绍RAG 系统的相关背景、定义以及基本组成，详细介绍RAG 系统的常\n见架构，讨论RAG 系统中知识检索与生成增强部分的技术细节，并介绍RAG 系\n统的应用与前景。 * 本书持续更新，GIT Hub 链接为：https://github. com/ZJU-LLMs/Foundations-of-LLMs。 第6 章检索增强生成\n6. 1 检索增强生成简介\n检索增强生成（RAG）旨在通过检索和整合外部知识来增强大语言模型生成\n文本的准确性和丰富性，其是一个集成了外部知识库、信息检索器、大语言模型等\n多个功能模块的系统。 RAG 利用信息检索、深度学习等多种技术为大语言模型在\n生成过程中引入最新的、特定领域的知识，从而克服传统大语言模型的局限性，提\n供更加精准和可靠的生成内容。 本节我们将主要介绍RAG 系统的相关背景、定义\n以及基本组成。 6. 1. 1 检索增强生成的背景\n大语言模型在多种生成任务上展现出了令人惊艳的能力，其可以辅助我们撰\n写文案、翻译文章、编写代码等。 但是，大模型生成的内容可能存在“幻觉”现象\n——生成内容看似合理但实际上逻辑混乱或与事实相悖。 这导致大语言模型生成\n内容的可靠性下降。 “幻觉”现象可能源于大语言模型所采用的训练数据，也可能\n源于模型本身。 1. 训练数据导致的幻觉\n训练数据是大语言模型知识的根本来源。 训练数据在采集完成后直接用于训\n练模型。 但是其中包含的知识可能在模型训练后又发生了更新。"
        },
        {
          "chunk_id": "719f851d-9437-45df-b03d-0e630b2edfed_chunk_16",
          "title": "第6章 检索增强生成",
          "doc_id": "719f851d-9437-45df-b03d-0e630b2edfed",
          "distance": 0.7064617276191711,
          "chunk_content": "第6 章检索增强生成\n型，使得两者能够在训练过程中相互适应，从而提高整体系统的性能。尽管白盒增\n强架构可以有效改善RAG 的性能，但也存在明显缺点。这种架构通常需要大量计\n算资源和时间来训练，特别是协同微调策略，需要大量的运算资源来实现语言模\n型和检索器的同步更新。 6.3 知识检索\n在RAG 中，检索的效果（召回率、精度、多样性等）会直接影响大语言模型\n的生成质量。以“树袋熊一般在哪里生活？”这个问题为例。如果检索器返回的外\n部知识是关于“树袋熊”名称相近的动物“袋熊”的相关知识，那么这些不正确的\n外部知识可能引导大语言模型生成错误答案。此外，检索的时间也是RAG 总耗时\n的关键部分，因此检索的效率将影响用户的使用体验。优化检索过程，提升检索的\n效果和效率，对改善RAG 的性能具有重要意义。针对优化检索过程，本节系统的\n对知识库构建、查询增强、检索器、检索结果重排序等关键技术进行梳理和介绍。 6.3.1 知识库构建\n知识库构成了RAG 系统的根基。正如古语所言：“巧妇难为无米之炊”，只有\n构建了全面、优质、高效的知识库，检索才能有的放矢，检索效果才能有保障。在\nRAG 框架中，知识库构建主要涉及数据采集及预处理与知识库增强两个步骤。本\n小节将对这两个步骤分别展开介绍。 1. 数据采集及预处理\n数据采集与预处理为构建知识库提供“原材料”。在构建文本型知识库的数据\n采集过程中，来自不同渠道的数据被整合、转换为统一的文档对象。这些文档对象\n不仅包含原始的文本信息，还携带有关文档的元信息（Metadata）。元信息可以用"
        },
        {
          "chunk_id": "719f851d-9437-45df-b03d-0e630b2edfed_chunk_10",
          "title": "第6章 检索增强生成",
          "doc_id": "719f851d-9437-45df-b03d-0e630b2edfed",
          "distance": 0.7474782466888428,
          "chunk_content": "第6 章检索增强生成\n在RAG 系统中，除了调整检索器和大语言模型，我们也可对其他功能模块（如\n知识库中的向量[17, 45]）进行调整。调整其他功能模块与黑盒增强和白盒增强的\n分类是兼容的。本节接下来的部分将详细介绍黑盒增强架构和白盒增强架构，并\n探讨它们代表性方法。 6.2.2 黑盒增强架构\n在某些情况下，由于无法获取大语言模型的结构和参数或者没有足够的算力\n对模型进行微调，例如只能通过API 进行交互时，我们不得不将语言模型视为一\n个黑盒。此时，RAG 需要在黑盒增强架构的基础上构建。在黑盒增强架构中，我\n们仅可对检索器进行策略调整与优化。其可以分为无微调架构和检索器微调两种\n架构。接下来对两种架构类型分别展开介绍。 1. 无微调\n无微调架构是所有RAG 架构中形式最简单的。该架构中，检索器和语言模\n型经过分别独立的预训练后参数不再更新，直接组合使用。这种架构对计算资源\n需求较低，方便实现且易于部署，适合于对部署速度和灵活性有较高要求的场景。 In-Context RALM[42] 是该框架下的代表性方法。其直接将检索器检索到的文档前\n置到输入问题前作为上下文，方法示意图如图6.10所示。In-Context RALM 包括检\n索和生成两个阶段。在检索阶段，输入的问题或部分句子作为查询从知识库中检\n索出相关文档。在生成阶段，这些检索到的文档被直接拼接到Prompt 中的上下文\n部分，然后将Prompt 输入给大语言模型。一个RAG 任务可能涉及多次执行检索和\n生成。例如，在一个长文本生成任务中，每生成一定量的文本后，模型就可能会执\n行一次检索，以确保随着话题的发展，后续生成的内容能够持续保持与话题相关。 在执行检索操作时，需要仔细选择几个关键参数，如检索步长和检索查询长\n度。检索步长是指模型在生成文本时，每隔多少个词进行一次检索，这一参数的设"
        }
      ],
      "metadata": {
        "retrieved_count": 4,
        "context_length": 3442
      }
    }
  ]
}